{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Sentiment Analysis API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'storage' from 'google.cloud' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aa94f5d7d204>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlanguage_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_v1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menums\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msleep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'storage' from 'google.cloud' (unknown location)"
     ]
    }
   ],
   "source": [
    "from google.cloud import language_v1\n",
    "from google.cloud.language_v1 import enums\n",
    "from google.cloud import storage\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "pandas.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv_from_gcs(csv_file, drop = 1):\n",
    "    df = pd.read_csv(csv_file, encoding = \"ISO-8859-1\")\n",
    "    df.fillna(\"\", inplace=True)\n",
    "    return df\n",
    "\n",
    "# Aquí podriamos agregar una columna de estas por prueba (opción a)\n",
    "# e.g. g_score_adjs_en, g_magnitude_adjs_en, etc\n",
    "def add_score_magnitude_cols(dataframe):\n",
    "    dataframe[\"g_score\"] = \"\"\n",
    "    dataframe[\"g_magnitude\"] = \"\"\n",
    "    \n",
    "# o bien separar el dataframe con solo las columnas  (opción b)\n",
    "# y a este nuevo df le agregamos las columnas de g_score y g_magnnitude\n",
    "def select_cols(dataframe, language = 'es', char = 'complete'):\n",
    "    if language == 'es':\n",
    "        if char == 'complete':\n",
    "            df = dataframe[['missing_info', 'improvements']]\n",
    "            return df\n",
    "        if char == 'adj':\n",
    "            df = dataframe[['missing_info'+'_'+char, 'improvements'+'_'+char]]\n",
    "            return df\n",
    "        if char == 'noun_adj':\n",
    "            df = dataframe[['missing_info'+'_'+char, 'improvements'+'_'+char]]\n",
    "            return df\n",
    "        \n",
    "    if language == 'en':\n",
    "        if char == 'complete':\n",
    "            df = dataframe[['missing_info'+'_'+language, 'improvements'+'_'+language]]\n",
    "            return df\n",
    "        if char == 'adj':\n",
    "            df = dataframe[['missing_info'+'_'+language+'_'+char, 'improvements'+'_'+language+'_'+char]]\n",
    "            return df\n",
    "        if char == 'noun_adj':\n",
    "            df = dataframe[['missing_info'+'_'+language+'_'+char, 'improvements'+'_'+language+'_'+char]]\n",
    "            return df\n",
    "    \n",
    "def analyze_sentiment(gcs_content_uri, client, language):\n",
    "    \"\"\"\n",
    "    Analyzing Sentiment in text file stored in Cloud Storage\n",
    "    Args:\n",
    "      -gcs_content_uri Google Cloud Storage URI where the file content is located.\n",
    "       e.g. gs://[Your Bucket]/[Path to File]\n",
    "      -client:\n",
    "       e.g. language_v1.LanguageServiceClient()\n",
    "      -language: 'es' or 'en'\n",
    "       For list of supported languages:\n",
    "       https://cloud.google.com/natural-language/docs/languages\n",
    "    \"\"\"    \n",
    "    if gcs_content_uri == \"\":\n",
    "        return \"\"\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "    document = {\"content\": gcs_content_uri, \"type\": type_, \"language\": language}\n",
    "    encoding_type = enums.EncodingType.UTF8\n",
    "    response = client.analyze_sentiment(document, encoding_type=encoding_type)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis option a):\n",
    "gcs_path = sys.argv[1]\n",
    "output_bucket = sys.argv[2]\n",
    "output_csv_file = sys.argv[3]\n",
    "\n",
    "df = parse_csv_from_gcs(gcs_path)\n",
    "add_score_magnitude_cols(df)\n",
    "cols = ['missing_info', 'improvements', 'missing_info_en', 'improvements_en',\n",
    "               'missing_info_adj', 'improvements_adj', 'missing_info_noun_adj', \n",
    "               'improvements_noun_adj', 'missing_info_en_adj','improvements_en_adj',\n",
    "               'missing_info_en_noun_adj', 'improvements_en_noun_adj']\n",
    "\n",
    "client = language_v1.LanguageServiceClient()\n",
    "lang = 'es'\n",
    "\n",
    "for i in df.index:\n",
    "    response = analyze_sentiment(df.at[i, cols[1]], client, language = lang)\n",
    "    df.at[i, 'g_core'] = response.document_sentiment.score\n",
    "    df.at[i, 'g_magnitude'] = response.document_sentiment.magnitude\n",
    "    sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis option b):\n",
    "\n",
    "gcs_path = sys.argv[1]\n",
    "output_bucket = sys.argv[2]\n",
    "output_csv_file = sys.argv[3]\n",
    "\n",
    "lang = 'es'\n",
    "\n",
    "dataframe = parse_csv_from_gcs(gcs_path)\n",
    "df = select_cols(dataframe, language = lang, char = 'complete')\n",
    "add_score_magnitude_cols(df)\n",
    "missing_info = df.columns[0]\n",
    "improvements = df.columns[1]\n",
    "\n",
    "client = language_v1.LanguageServiceClient()\n",
    "\n",
    "for i in df.index:\n",
    "    response = analyze_sentiment(df.at[i, missing_info], client,language = lang)\n",
    "    df.at[i, 'g_core'] = response.document_sentiment.score\n",
    "    df.at[i, 'g_magnitude'] = response.document_sentiment.magnitude\n",
    "    sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data\n",
    "df.to_csv(\"survey_results.csv\", encoding = 'ISO-8859-1')\n",
    "\n",
    "gcs = storage.Client()\n",
    "gcs.get_bucket(output_bucket).blob(output_csv_file).upload_from_filename('survey_results.csv', content_type='text/csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
